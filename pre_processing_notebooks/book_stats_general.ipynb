{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_PATH = Path.home() / \"SEED_DATA/impact_and_fiction/\"\n",
    "\n",
    "work_isbn_genre = ROOT_PATH / \"work_isbn_genre.tsv\"\n",
    "df = pd.read_csv(work_isbn_genre, sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "def get_isbn_from_filename(filename: str):\n",
    "    return filename.split('_')[1].split('-')[0]\n",
    "\n",
    "def get_isbn_from_filenames(filenames: list[str]):\n",
    "    return [get_isbn_from_filename(x) for x in filenames]\n",
    "\n",
    "def get_book_content(dir_name, file_name, idx):\n",
    "    all_words = []\n",
    "    print(f\"{idx} unzipping: {file_name}\")\n",
    "    for idxx,line in enumerate(gzip.open(os.path.join(dir_name, file_name),'rt')):\n",
    "        words = [word.lower() for word in line.split()]\n",
    "        all_words.extend(words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Valid Files in novels_tokens folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "novels_tokens = ROOT_PATH / \"novels_tokens\"\n",
    "\n",
    "limit = -1\n",
    "token_data = []\n",
    "for idx,file_name in enumerate(os.listdir(novels_tokens)):\n",
    "    book_tokens = [] # get_book_content(novels_tokens, file_name, idx)\n",
    "    token_data.append((get_isbn_from_filename(file_name), file_name, len(book_tokens)))\n",
    "    if idx == limit: break\n",
    "\n",
    "token_df = pd.DataFrame(token_data, columns=['isbn','book_filename', 'token_count'])\n",
    "token_df = token_df.set_index('book_filename')\n",
    "\n",
    "filename2isbn = token_df.to_dict(orient='index')\n",
    "json.dump(filename2isbn, open(\"data/filename2isbn.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
    "\n",
    "token_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the definitive lists of unique ISBNs (Partitioned in Fiction vs Non-Fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_isbns_df(filename, skip_files = None):\n",
    "    volatility = pd.read_csv(filename)\n",
    "    volatility['isbn'] = [i.split('_')[1] for i in volatility.book]\n",
    "    if skip_files:\n",
    "        isbns_only = [x.split('_')[1].split('-')[0] for x in skip_files]\n",
    "        with open(\"data/non_fiction_isbns.txt\", \"w\") as f:\n",
    "            [f.write(x+\"\\n\") for x in isbns_only]\n",
    "        volatility = volatility[~volatility.isbn.isin(isbns_only)]\n",
    "    volatility = volatility.drop(columns=['book'])\n",
    "    volatility = volatility.set_index('isbn')\n",
    "    return volatility\n",
    "\n",
    "skip_files = open(\"non_fiction_filenames.txt\").read().splitlines()\n",
    "\n",
    "# Any volatility output file should work. The total number of unique books is 18,467. The completely non-fiction books are 5,257\n",
    "filename = \"/Users/jose/SEED_DATA/impact_and_fiction/volatilities/book_moors_volatility_300_few_words_normal.csv\"\n",
    "df = get_unique_isbns_df(filename, skip_files)\n",
    "\n",
    "isbns = list(df.index)\n",
    "with open(\"data/fiction_isbns.txt\", \"w\") as f:\n",
    "    [f.write(x+\"\\n\") for x in isbns]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
